{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":82695,"databundleVersionId":9738540,"sourceType":"competition"},{"sourceId":9688062,"sourceType":"datasetVersion","datasetId":5920031},{"sourceId":9972502,"sourceType":"datasetVersion","datasetId":6135443},{"sourceId":10182913,"sourceType":"datasetVersion","datasetId":6252126},{"sourceId":212205726,"sourceType":"kernelVersion"},{"sourceId":212206270,"sourceType":"kernelVersion"},{"sourceId":118192,"sourceType":"modelInstanceVersion","modelInstanceId":99392,"modelId":123481},{"sourceId":167864,"sourceType":"modelInstanceVersion","modelInstanceId":142811,"modelId":165390},{"sourceId":174909,"sourceType":"modelInstanceVersion","modelInstanceId":148911,"modelId":171421},{"sourceId":174921,"sourceType":"modelInstanceVersion","modelInstanceId":148923,"modelId":171434},{"sourceId":185986,"sourceType":"modelInstanceVersion","modelInstanceId":158570,"modelId":180936}],"dockerImageVersionId":30840,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# <div style=\"text-align: left ; padding: 12px; line-height:2; border-radius:1px; margin-bottom: 0em; text-align: center; font-size: 50px;border-style: solid;border-color: dark green; font-weight: bold;\">Eedi - Mining Misconceptions in Mathematics</div>\n\n\nNguồn Kaggle Notebook ở [đây](https://www.kaggle.com/code/caokhoihuynh/model-final?scriptVersionId=218454004&fbclid=IwZXh0bgNhZW0CMTEAAR1vv1y8gBS45HwXKMv7O7cztm_Bdo-2Uo1a1Jj5Tlpdd4WJkPOwKCg_Ajw_aem_5NYEweFy-Rfb7ZsqLTWw5A)\n# **1. Importing Libraries**","metadata":{}},{"cell_type":"markdown","source":"Đầu tiên, nhóm sẽ tải một số thư viện cần thiết","metadata":{}},{"cell_type":"code","source":"%%capture\n!pip install --no-index --find-links=/kaggle/input/eedi-libraries-dataset autoawq bitsandbytes==0.45.0 peft==0.14.0 vllm==0.5.3.post1 logits-processor-zoo==0.1.0 triton","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-16T15:07:19.777254Z","iopub.execute_input":"2025-01-16T15:07:19.777579Z","iopub.status.idle":"2025-01-16T15:10:00.586531Z","shell.execute_reply.started":"2025-01-16T15:07:19.777552Z","shell.execute_reply":"2025-01-16T15:10:00.585509Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import json\nimport time\nimport numpy as np\nimport pandas as pd\n\nimport torch\nimport torch.nn.functional as F\nfrom torch import Tensor\n\nfrom argparse import ArgumentParser\nfrom dataclasses import dataclass\nfrom pathlib import Path\nfrom typing import Literal\n\nfrom transformers import (\n    AutoModel,\n    AutoTokenizer,\n    BitsAndBytesConfig,\n    PreTrainedModel,\n    PreTrainedTokenizerBase,\n)\n\nfrom vllm import LLM, SamplingParams\nfrom peft import LoraConfig, PeftModel, get_peft_model \nfrom logits_processor_zoo.vllm import GenLengthLogitsProcessor, CiteFromPromptLogitsProcessor, ForceLastPhraseLogitsProcessor, MultipleChoiceLogitsProcessor\n\nfrom sklearn.neighbors import NearestNeighbors\n\nfrom tqdm.auto import tqdm","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-16T15:10:00.58808Z","iopub.execute_input":"2025-01-16T15:10:00.588389Z","iopub.status.idle":"2025-01-16T15:10:26.014097Z","shell.execute_reply.started":"2025-01-16T15:10:00.588357Z","shell.execute_reply":"2025-01-16T15:10:26.013282Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **2. Preprocessing**\n\nỞ bước này, nhóm sẽ tiến hành xử lý dữ liệu đầu vào, đưa về định dạng phù hợp để tạo câu truy vấn, làm đầu vào cho các bước suy luận sau. Quá trình này bao gồm 2 hàm chính sau: \n\n- `preprocessing_df`: Hàm này nhận đầu vào là dòng dữ liệu từ định dạng thô (các câu hỏi với 4 đáp án trên một dòng), chuẩn hóa, chuyển đổi nó sang định dạng mỗi dòng tương ứng với một câu hỏi và một đáp án (đúng hoặc sai), cùng các dữ liệu liên quan, phục vụ cho việc tạo template câu query ở bước sau.\n\n- `make_complete_query`: Tạo một câu truy vấn hoàn chỉnh (query) theo định dạng một chuỗi văn bản hoàn từ một dòng dữ liệu, bao gồm thông tin về \"SUBJECT\", \"CONSTRUCT\", \"QUESTION\", \"CORRECT ANSWER\", và \"WRONG ANSWER\".\n\n\nLưu đoạn code vào file `utils.py`","metadata":{}},{"cell_type":"code","source":"%%writefile utils.py\nimport pandas as pd\n\ndef make_complete_query(row: pd.Series) -> str:\n   \n    template = \"SUBJECT: {}\\n\\nCONSTRUCT: {}\\n\\nQUESTION: {}\\n\\nCORRECT ANSWER: {}\\n\\nWRONG ANSWER: {}\"\n    return template.format(\n                            row[\"SubjectName\"],\n                            row[\"ConstructName\"],\n                            row[\"QuestionText\"],\n                            row[\"CorrectText\"],\n                            row[\"WrongText\"],\n                        )\n\n\ndef preprocessing_df(df: pd.DataFrame) -> pd.DataFrame:\n    \n    # 1. Tạo cột CorrectText\n    df = df.copy()\n    df = df.rename(columns={\"CorrectAnswer\": \"CorrectChoice\"})\n    df[\"CorrectText\"] = df.apply(lambda x: x[f\"Answer{x['CorrectChoice']}Text\"], axis=1)\n    \n    # 2. Tiến hành phân tách các câu trả lời thành từng dòng khác nhau\n    df_melted_ans = pd.melt(\n        df,\n        id_vars=[  # what column to keep\n            \"QuestionId\",\n            \"ConstructId\",\n            \"ConstructName\",\n            \"SubjectId\",\n            \"SubjectName\",\n            \"CorrectChoice\",\n            \"CorrectText\",\n            \"QuestionText\",\n        ],\n        value_vars=[ \n            \"AnswerAText\",\n            \"AnswerBText\",\n            \"AnswerCText\",\n            \"AnswerDText\",\n        ],\n        var_name=\"WrongChoice\", \n        value_name=\"WrongText\",  \n    )\n\n    # Chuẩn hóa định dạng câu trả lời\n    df_melted_ans[\"WrongChoice\"] = df_melted_ans[\"WrongChoice\"].str[6]\n    df_melted_ans = df_melted_ans.sort_values([\"QuestionId\", \"WrongChoice\"])\n    df_melted_ans = df_melted_ans.reset_index(drop=True)\n    \n    try:\n        # 3. Tách các misconceptions (chỉ dùng cho tập Train)\n        df_melted_mis = pd.melt(\n            df,\n            id_vars=[\"QuestionId\"],\n            value_vars=[\n                \"MisconceptionAId\",\n                \"MisconceptionBId\",\n                \"MisconceptionCId\",\n                \"MisconceptionDId\",\n            ],\n            var_name=\"_melted_mis_header\",\n            value_name=\"MisconceptionId\",\n        )\n        df_melted_mis = df_melted_mis.sort_values([\"QuestionId\", \"_melted_mis_header\"])\n        df_melted_mis = df_melted_mis.drop(columns=[\"QuestionId\", \"_melted_mis_header\"])\n        df_melted_mis = df_melted_mis.reset_index(drop=True)\n        \n        assert len(df_melted_ans) == len(df_melted_mis)\n        df_preprocessed = pd.concat([df_melted_ans, df_melted_mis], axis=1)\n        \n    except KeyError:\n        df_preprocessed = df_melted_ans\n        \n    # 5. Loại bỏ các dòng dữ liệu của đáp án đúng, ko cần thiết cho việc dự đoán misconception\n    df_preprocessed = df_preprocessed[(df_preprocessed[\"WrongChoice\"] != df_preprocessed[\"CorrectChoice\"])]\n    try:\n        df_preprocessede = df_preprocessed[df_preprocessed[\"MisconceptionId\"].notna()]\n        df_preprocessed[\"MisconceptionId\"] = df_preprocessed[\"MisconceptionId\"].astype(int)\n    except KeyError:\n        pass\n    df_preprocessed = df_preprocessed.reset_index(drop=True)\n    df_preprocessed[\"QuestionId_Answer\"] = (\n        df_preprocessed[\"QuestionId\"].astype(str) + \"_\" + df_preprocessed[\"WrongChoice\"]\n    )\n    return df_preprocessed","metadata":{"execution":{"iopub.status.busy":"2025-01-16T15:10:26.016112Z","iopub.execute_input":"2025-01-16T15:10:26.016752Z","iopub.status.idle":"2025-01-16T15:10:26.023088Z","shell.execute_reply.started":"2025-01-16T15:10:26.016724Z","shell.execute_reply":"2025-01-16T15:10:26.022057Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **3. Stage 1: Retrieval**","metadata":{}},{"cell_type":"markdown","source":"Đây là bước đầu tiên của pipeline, với nhiệm vụ tạo các embeddings cho từng query, từng misconception, và tính toán độ tương đồng giữa chúng để tìm ra các misconception phù hợp với query.\n\n- `last_token_pool`: Trích xuất đặc trưng (feature) từ `last_hidden_states` của một mô hình ngôn ngữ, bằng cách chọn token cuối cùng có ý nghĩa từ mỗi chuỗi đầu vào, dựa trên `attention_mask`.\n\n- `get_embeddings_in_batches`: Tạo embedding từ một danh sách các văn bản (texts) bằng cách sử dụng mô hình ngôn ngữ đã được huấn luyện trước và tokenizer. Hàm này xử lý dữ liệu theo từng batch nhỏ để tối ưu hóa việc sử dụng bộ nhớ GPU và tăng hiệu suất tính toán.\n\n- `template`: Các hàm tạo các template truy vấn khác nhau cho các mô hình.\n\n- `retrieval_flow`: Các hàm chính thực hiện quá trình suy luận cho từng mô hình. Hàm này bao gồm việc tải dữ liệu, mô hình, tokenizer; và tính toán embedding cho question và misconceptions.\n\n- Hàm `main`:\n    - Tải dữ liệu từ các file CSV chứa các câu hỏi và misconceptions.\n    - Gọi retrieval_flow để tính toán embedding cho câu hỏi và misconception.\n    - Định dạng lại ma trận embedding.\n    - Sử dụng thuật toán NearestNeighbors để tìm top 25 misconception gần nhất cho từng câu hỏi dựa trên khoảng cách Cosine.\n    - Lưu kết quả (danh sách top 25 misconception) vào file JSON.","metadata":{}},{"cell_type":"code","source":"%%writefile infer_top25_ensemble.py\n# Tạo một file Python để chạy inference trên mô hình.\n# Bao gồm việc tải dữ liệu, sử dụng mô hình LoRA, và xử lý logits.\n\nimport gc\nimport json\nimport numpy as np\nimport pandas as pd\n\nimport torch\nfrom torch import Tensor\nimport torch.nn.functional as F\n\nfrom peft import LoraConfig, PeftModel, get_peft_model\n\nfrom sklearn.neighbors import NearestNeighbors\n\nfrom tqdm.auto import tqdm\nfrom transformers import (\n    AutoModel,\n    AutoTokenizer,\n    BitsAndBytesConfig,\n    PreTrainedTokenizerBase,\n)\n\nfrom utils import  preprocessing_df\n\n\ndef last_token_pool(last_hidden_states: Tensor, attention_mask: Tensor) -> Tensor:\n    left_padding = attention_mask[:, -1].sum() == attention_mask.shape[0]\n    if left_padding:\n        return last_hidden_states[:, -1]\n    else:\n        sequence_lengths = attention_mask.sum(dim=1) - 1\n        batch_size = last_hidden_states.shape[0]\n        return last_hidden_states[\n            torch.arange(batch_size, device=last_hidden_states.device), sequence_lengths\n        ]\n\ndef get_embeddings_in_batches( \n                                model,\n                                tokenizer: PreTrainedTokenizerBase,\n                                texts: list[str],\n                                max_length: int,\n                                batch_size: int,\n                                desc: str,\n                            ):\n    embeddings = []\n    \n    for i in tqdm(range(0, len(texts), batch_size), desc=desc):\n        batch_texts = texts[i : i + batch_size]\n        batch_dict = tokenizer( batch_texts, max_length=max_length, padding=True, truncation=True, return_tensors=\"pt\").to(\"cuda\")\n        \n        with torch.no_grad(), torch.autocast(\"cuda\"):\n            outputs = model(**batch_dict)\n            batch_embeddings = last_token_pool(\n                outputs.last_hidden_state,\n                batch_dict[\"attention_mask\"],  # type: ignore\n            )\n            batch_embeddings = F.normalize(batch_embeddings, p=2, dim=1).cpu()\n            \n        embeddings.append(batch_embeddings)\n    return torch.cat(embeddings, dim=0)\n\ndef template(row: pd.Series) -> str:\n    template = \"\"\"Instruct: Given a math question with correct answer and a misconcepted incorrect answer, retrieve the most accurate misconception for the incorrect answer.\nQuery: \n### SubjectName: {subject}\n### ConstructName: {construct}\n### Question: {question}\n### Correct Answer: {correct}\n### Misconcepte Incorrect answer: {wrong}\n<response>\"\"\"\n    return template.format(\n        question=row[\"QuestionText\"],\n        subject=row[\"SubjectName\"],\n        construct=row[\"ConstructName\"],\n        correct=row[\"CorrectText\"],\n        wrong=row[\"WrongText\"],\n    )\n\n\ndef retrieval_flow( df_test: pd.DataFrame, df_mis: pd.DataFrame, model_path: str, lora_path: str, tokenizer_path: str,) -> tuple[Tensor, Tensor]:\n    \n    # 1. Xử lý dữ liệu để thu được tập query và misconception\n    queries = df_test.apply(template, axis=1).tolist()\n    misconceptions = df_mis[\"MisconceptionName\"].tolist()\n    \n    # 2. Tải model và lấy Tokenizer\n    bnb_config = BitsAndBytesConfig(\n        load_in_4bit=True,\n        bnb_4bit_use_double_quant=True,\n        bnb_4bit_quant_type=\"nf4\",\n        bnb_4bit_compute_dtype=torch.bfloat16,\n    )\n    model = AutoModel.from_pretrained(\n        model_path,\n        quantization_config=bnb_config,\n        device_map=\"cuda:0\",\n        trust_remote_code=True,\n    )\n    tokenizer = AutoTokenizer.from_pretrained(tokenizer_path)\n    model.resize_token_embeddings(len(tokenizer))\n    model = PeftModel.from_pretrained(model, lora_path)\n    \n    # 3. Thực hiện trích xuất embeddings theo từng batch\n    q_embeds = get_embeddings_in_batches(\n        model, tokenizer, queries, max_length=512, batch_size=4, desc=\"Query embeddings\"\n    )\n    m_embeds = get_embeddings_in_batches(\n        model, tokenizer, misconceptions, max_length=512, batch_size=4, desc=\"Misconception embeddings\"\n    )\n    return q_embeds, m_embeds\n\n\ndef main():\n \n    df_mis = pd.read_csv(\"/kaggle/input/eedi-mining-misconceptions-in-mathematics/misconception_mapping.csv\")\n    df_test = pd.read_csv(\"/kaggle/input/eedi-mining-misconceptions-in-mathematics/test.csv\")\n    df_test =  preprocessing_df(df_test)\n\n    all_q_embeds = []\n    all_m_embeds = []\n\n    q_embeds, m_embeds = retrieval_flow(\n       df_test,\n       df_mis,\n       model_path=\"/kaggle/input/qwen2.5-14/pytorch/default/1\",\n       lora_path=\"/kaggle/input/14b-cp750/pytorch/default/1/checkpoint-750\",\n       tokenizer_path=\"/kaggle/input/14b-cp750/pytorch/default/1/checkpoint-750\",\n    )\n    all_q_embeds.append(q_embeds)\n    all_m_embeds.append(m_embeds)\n    gc.collect()\n    torch.cuda.empty_cache()\n\n   \n    all_q_embeds = np.concatenate(all_q_embeds, axis=-1)\n    all_m_embeds = np.concatenate(all_m_embeds, axis=-1)\n\n    # calc\n    nn = NearestNeighbors(n_neighbors=25, algorithm=\"brute\", metric=\"cosine\")\n    nn.fit(all_m_embeds)\n    dist, topk_mis = nn.kneighbors(all_q_embeds)\n\n    # save\n    savepath = \"top25_miscons.json\"\n    with open(savepath, \"w\") as f:\n        json.dump(topk_mis.tolist(), f)\n    print(f\"saved to {savepath}\")\n\n\nif __name__ == \"__main__\":\n    main()","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true,"execution":{"iopub.status.busy":"2025-01-16T15:10:26.02443Z","iopub.execute_input":"2025-01-16T15:10:26.024758Z","iopub.status.idle":"2025-01-16T15:10:26.060661Z","shell.execute_reply.started":"2025-01-16T15:10:26.024724Z","shell.execute_reply":"2025-01-16T15:10:26.059697Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!python infer_top25_ensemble.py","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-16T15:10:26.061664Z","iopub.execute_input":"2025-01-16T15:10:26.061896Z","iopub.status.idle":"2025-01-16T15:19:26.559092Z","shell.execute_reply.started":"2025-01-16T15:10:26.06187Z","shell.execute_reply":"2025-01-16T15:19:26.558179Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **4. Stage 2: Re-ranking**\n\nĐây là bước thứ 2 trong pipeline, với mục tiêu là sắp xếp lại thứ tự của 9 misconceptions đầy tiên, dựa trên kết quả của mô hình `Qwen 2.5 32B`, kết hợp với `Multiple Choice Logits Processor`, được dùng trong tình huống các bài toán trắc nghiệm, đảm bảo định dạng đầu ra là các lựa chọn phù hợp.","metadata":{}},{"cell_type":"code","source":"import json\nimport time\nimport numpy as np\nimport pandas as pd\n\n\nimport torch\n\nfrom argparse import ArgumentParser\nfrom dataclasses import dataclass\nfrom pathlib import Path\nfrom typing import Literal\n\n\nfrom sklearn.neighbors import NearestNeighbors\nfrom transformers import (\n    AutoModel,\n    AutoTokenizer,\n    BitsAndBytesConfig,\n    PreTrainedModel,\n    PreTrainedTokenizerBase,\n)\n\nfrom vllm import LLM, SamplingParams\nfrom logits_processor_zoo.vllm import MultipleChoiceLogitsProcessor\n\nfrom utils import make_complete_query, preprocessing_df","metadata":{"execution":{"iopub.status.busy":"2025-01-16T15:19:26.560184Z","iopub.execute_input":"2025-01-16T15:19:26.560516Z","iopub.status.idle":"2025-01-16T15:19:26.568088Z","shell.execute_reply.started":"2025-01-16T15:19:26.560481Z","shell.execute_reply":"2025-01-16T15:19:26.567419Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Bước 1: Tải và chuẩn bị dữ liệu\n# Tải và xử lý dữ liệu misconception từ file CSV.\ndf_mis = pd.read_csv(\"/kaggle/input/eedi-mining-misconceptions-in-mathematics/misconception_mapping.csv\")\norig_mis = df_mis[\"MisconceptionName\"].tolist()\n\n# Tải và tiền xử lý dữ liệu test từ file CSV.\ndf_test = pd.read_csv(\"/kaggle/input/eedi-mining-misconceptions-in-mathematics/test.csv\")\ndf_test = preprocessing_df(df_test)\n\n# Tạo câu truy vấn đầy đủ .\ndf_test[\"QuestionComplete\"] = df_test.apply(make_complete_query, axis=1)\n\n# # Thêm danh sách top 25 misconception gần nhất cho mỗi câu hỏi từ file \"top25_miscons.json\"\nwith open(\"/kaggle/working/top25_miscons.json\", \"r\") as f:\n    top25_miscons = json.load(f)\n    \ndf_test[\"Top25Miscons\"] = top25_miscons","metadata":{"execution":{"iopub.status.busy":"2025-01-16T15:19:26.568858Z","iopub.execute_input":"2025-01-16T15:19:26.569102Z","iopub.status.idle":"2025-01-16T15:19:26.620294Z","shell.execute_reply.started":"2025-01-16T15:19:26.569082Z","shell.execute_reply":"2025-01-16T15:19:26.619568Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Bước 2: Chuẩn bị mô hình Qwen 2.5 32B\n# Khởi tạo mô hình LLM và lấy tokenizer\nllm = LLM(\n    \"/kaggle/input/qwen2.5/transformers/32b-instruct-awq/1\",\n    quantization=\"awq\",\n    tensor_parallel_size=2,\n    gpu_memory_utilization=0.90, \n    trust_remote_code=True,\n    dtype=\"half\", \n    enforce_eager=True,\n    max_model_len=5120,\n    disable_log_stats=True,\n)\ntokenizer = llm.get_tokenizer()","metadata":{"execution":{"iopub.status.busy":"2025-01-16T15:19:26.622535Z","iopub.execute_input":"2025-01-16T15:19:26.622789Z","iopub.status.idle":"2025-01-16T15:22:12.140788Z","shell.execute_reply.started":"2025-01-16T15:19:26.622768Z","shell.execute_reply":"2025-01-16T15:22:12.139682Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def generate_numbering_seq(k: int, kind: Literal[\"number\", \"alphabet\"]) -> list[str]:\n    if kind == \"number\":\n        return [str(i) for i in range(1, k + 1)]\n    elif kind == \"alphabet\":\n        return [chr(ord(\"A\")+i) for i in range(k)]\n    assert False\n","metadata":{"execution":{"iopub.status.busy":"2025-01-16T15:22:12.142639Z","iopub.execute_input":"2025-01-16T15:22:12.143138Z","iopub.status.idle":"2025-01-16T15:22:12.148487Z","shell.execute_reply.started":"2025-01-16T15:22:12.143091Z","shell.execute_reply":"2025-01-16T15:22:12.147697Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Khởi tạo số lượng misconceptions đầu tiên cần sắp xếp\nRERANK = 9\n\n# Tạo prompt để gửi tới mô hình LLM.\ndef make_llm_prompt(\n    row: pd.Series,\n    k: int,\n    orig_mis: list[str],\n) -> str:\n    question = row[\"QuestionComplete\"]\n    top25_mis: list[int] = row[\"Top25Miscons\"] \n    template = \"You are an elite mathematics teacher tasked to assess the student's understanding of math concepts. Below, you will be presented with: the math question, the correct answer, the wrong answer and {k} possible misconceptions that could have led to the mistake.\\n\\n{question}\\n\\nPossible Misconceptions\\n{choices}\\n\\nSelect one misconception that leads to incorrect answer. Just output a single number of your choice and nothing else.\\n\\nAnswer: \"\n    numbered_mis_texts = []\n    for i, iseq in enumerate(generate_numbering_seq(k, \"number\")):\n        numbered_mis_texts.append(f\"{iseq}. {orig_mis[top25_mis[i]]}\")\n    numbered_mis_texts = \"\\n\".join(numbered_mis_texts)\n    llm_prompt = template.format(k=k, question=question, choices=numbered_mis_texts)\n    return llm_prompt\n\n\ndf_test[\"PromptEn\"] = df_test.apply(\n    lambda row: make_llm_prompt(row, 9, orig_mis), axis=1\n)","metadata":{"execution":{"iopub.status.busy":"2025-01-16T15:22:12.17002Z","iopub.execute_input":"2025-01-16T15:22:12.170268Z","iopub.status.idle":"2025-01-16T15:22:12.1883Z","shell.execute_reply.started":"2025-01-16T15:22:12.170247Z","shell.execute_reply":"2025-01-16T15:22:12.186885Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Bước 3: thực hiện quá trình sắp xếp dựa trên prompt và Multiple Choice Logits Processor\n# Tạo một bộ xử lý logits cho các câu hỏi trắc nghiệm (multiple choice)\nlogits_processor = MultipleChoiceLogitsProcessor(\n    tokenizer=tokenizer,\n    choices=generate_numbering_seq(RERANK, \"number\")\n)\n\n# Thiết lập các tham số cho sampling (sinh mẫu) khi gọi mô hình\nsampling_params = SamplingParams(\n    n=1,\n    temperature=0,\n    max_tokens=1,\n    logits_processors=[logits_processor],\n    logprobs=RERANK,\n)\n# Gọi mô hình LLM để sinh ra các phản hồi dựa trên các prompts.\nresponses = llm.generate(df_test[\"PromptEn\"].tolist(), sampling_params)\n","metadata":{"execution":{"iopub.status.busy":"2025-01-16T15:22:12.189304Z","iopub.execute_input":"2025-01-16T15:22:12.189628Z","iopub.status.idle":"2025-01-16T15:22:19.6193Z","shell.execute_reply.started":"2025-01-16T15:22:12.189594Z","shell.execute_reply":"2025-01-16T15:22:19.618282Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Thực hiện bước re-ranking các misconceptions dựa trên dự đoán từ mô hình LLM\nall_reranked = []\nfor resp, top25 in zip(responses, df_test[\"Top25Miscons\"]):\n    decoded_tokens = [logprob.decoded_token for logprob in resp.outputs[0].logprobs[0].values()]\n\n    # Chuyển các giá trị token về giá trị hệ số.\n    indices = [int(d) - 1 for d in decoded_tokens]\n    \n    # Sắp xếp lại top RERANK các misconception đầu\n    reranked = np.array(top25[:RERANK])[indices].tolist() + top25[RERANK:]\n    all_reranked.append(reranked)\n    \nassert len(all_reranked) == df_test.shape[0]","metadata":{"execution":{"iopub.status.busy":"2025-01-16T15:22:19.620136Z","iopub.execute_input":"2025-01-16T15:22:19.620389Z","iopub.status.idle":"2025-01-16T15:22:19.626647Z","shell.execute_reply.started":"2025-01-16T15:22:19.620357Z","shell.execute_reply":"2025-01-16T15:22:19.625792Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Bước 4: Tạo file submission\n# File chứa hai cột chính: cột ID question và cột ID Misconception\ndf_test[\"MisconceptionId\"] = [\" \".join(str(x) for x in row) for row in all_reranked]\n\ndf_sub = df_test[[\"QuestionId_Answer\", \"MisconceptionId\"]]\n\ndf_sub.to_csv(\"submission.csv\", index=False)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **5. Submission**","metadata":{}},{"cell_type":"code","source":"pd.read_csv(\"submission.csv\")","metadata":{"execution":{"iopub.status.busy":"2025-01-16T15:22:19.684168Z","iopub.execute_input":"2025-01-16T15:22:19.684418Z","iopub.status.idle":"2025-01-16T15:22:19.69585Z","shell.execute_reply.started":"2025-01-16T15:22:19.684397Z","shell.execute_reply":"2025-01-16T15:22:19.694943Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **6. References**\n\nBài làm được hòan thành dựa trên tham khảo từ các nguồn sau đây:\n\n- [Eedi Qwen32B vllm with logits-processor-zoo](https://www.kaggle.com/code/aerdem4/eedi-qwen32b-vllm-with-logits-processor-zoo/input?select=train.csv)\n- [86th Place Solution (just using public models)](https://www.kaggle.com/competitions/eedi-mining-misconceptions-in-mathematics/discussion/551659)\n- [EEDI_11_21_14B](https://www.kaggle.com/code/anhvth226/eedi-11-21-14b)\n- [Eedi qwen2.5-14b-it a simple infer](https://www.kaggle.com/code/zuoyouzuo/eedi-qwen2-5-14b-it-a-simple-infer-lb-0-422)\n- [Flag_qwen14b_test](https://www.kaggle.com/code/mschoo/flag-qwen14b-test)\n- https://huggingface.co/Salesforce/SFR-Embedding-2_R","metadata":{}}]}